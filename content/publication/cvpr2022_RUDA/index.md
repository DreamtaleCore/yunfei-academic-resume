---
title: "Generalizing Gaze Estimation with Rotation Consistency"
publication_types:
  - "1"
authors:
  - Yiwei Bao
  - Yunfei Liu
  - Haofei Wang
  - Feng Lu
publication: The 38th IEEE Conference on Computer Vision and Pattern Recognition
publication_short: CVPR
summary: "The 38th IEEE Conference on Computer Vision and Pattern Recognition *(CVPR-2022)*"
abstract: Recent advances of deep learning-based approaches have achieved remarkable performance on appearancebased gaze estimation. However, due to the shortage of target domain data and absence of target labels, generalizing gaze estimation algorithm to unseen environments is still challenging. In this paper, we discover the rotationconsistency property in gaze estimation and introduce the ‘sub-label’ for unsupervised domain adaptation. Consequently, we propose the Rotation-enhanced Unsupervised Domain Adaptation (RUDA) for gaze estimation. First, we rotate the original images with different angles for training. Then we conduct domain adaptation under the constraint of rotation consistency. The target domain images are assigned with sub-labels, derived from relative rotation angles rather than untouchable real labels. With such sublabels, we propose a novel distribution loss that facilitates the domain adaptation. We evaluate the RUDA framework on four cross-domain gaze estimation tasks. Experimental results demonstrate that it improves the performance over the baselines with gains ranging from 12.2% to 30.5%. Our framework has the potential to be used in other computer vision tasks with physical constraints.

draft: false
featured: false
tags:
  - Face Gaze
  - Domain adaptation
image:
  filename: featured.png
  focal_point: Smart
  preview_only: false
  caption: Teaser Image
date: 2022-10-01T14:07:22.714Z

links:
  - icon: ""
    icon_pack: fab
    name: PDF
    url: https://openaccess.thecvf.com/content/CVPR2022/papers/Bao_Generalizing_Gaze_Estimation_With_Rotation_Consistency_CVPR_2022_paper.pdf
---
