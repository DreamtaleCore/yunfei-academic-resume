---

title: "Separating Content and Style for Unsupervised Image-to-Image Translation"
publication_types:
  - "1"
authors:
  - "**Yunfei Liu**"
  - Haofei Wang
  - Yang Yue
  - Feng Lu
publication: The British Machine Vision Conference
publication_short: BMVC
summary: "The British Machine Vision Conference *(BMVC-2021)*"
abstract: "Unsupervised image-to-image translation aims to learn the mapping between two
visual domains with unpaired samples. Existing works focus on disentangling domaininvariant
content code and domain-specific style code individually for multimodal purposes.
However, less attention has been paid to interpreting and manipulating the translated
image. In this paper, we propose to separate the content code and style code simultaneously
in a unified framework. Based on the correlation between the latent features and
the high-level domain-invariant tasks, the proposed framework demonstrates superior
performance in multimodal translation, interpretability and manipulation of the translated
image. Experimental results show that the proposed approach outperforms the existing
unsupervised image translation methods in terms of visual quality and diversity."
tags:
  - Image-to-Image Translation
  - Interpretation
  - High-level Task
draft: false
featured: false

image:
  filename: featured.png
  focal_point: Smart
  preview_only: false
  caption: Teaser Image
date: 2021-10-21T13:56:00.000Z

links:
  - icon: ""
    icon_pack: fab
    name: PDF
    url: https://arxiv.org/abs/tbd
  - url: https://github.com/DreamtaleCore/SCS-UIT
    name: Code
    icon_pack: fab
    icon: "github"

---